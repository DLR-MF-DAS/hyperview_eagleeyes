"""
This code is generated by Ridvan Salih KUZU
LAST EDITED:  20.06.2022
ABOUT SCRIPT:
It runs linear probe training, validation and evaluation for given CLIP models
"""

import os
import clip
import torch

import argparse
import numpy as np
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from tqdm import tqdm
from collections import Counter

# from sklearnex import patch_sklearn
# patch_sklearn()
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_validate
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import pandas as pd
import matplotlib.pyplot as plt

import optuna
from optuna.samplers import TPESampler


def main(args):

    if not os.path.exists(args.log_dir):
        os.makedirs(args.log_dir)

    available_models = clip.available_models()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    #model, transform = clip.load(available_models[0], device)



    def objective(trial, features, labels):
        '''
            THIS FUNCTION DEFINES THE OBJECTIVE FUNCTION FOR BAYESIAN HYPERPARAMETER TUNING
            :param trial: trial object of bayesian optimization
            :param features: extracted feature vectors by using `CLIP.image_encoder`
            :param labels: class labels for the exploited dataset
            :return: returns weighted F1 score to be maximized
        '''

        print(f"INFO: Trial number: {trial.number}\n")

        reg_strength = trial.suggest_float("reg_strength", args.reg_strength[0], args.reg_strength[1], step=args.reg_strength[2])

        classifier = LogisticRegression(random_state=42, C=reg_strength, max_iter=1000, verbose=0, class_weight='balanced', n_jobs=-1)
        cv_results = cross_validate(classifier, features, labels, cv=5, scoring=('f1_weighted'))
        mean_f1 = np.mean(cv_results['test_score'])

        return mean_f1

    for idx, model_name in enumerate(available_models):

        print("[INFO]: Training started for model {} ...".format(model_name))

        model, transform = clip.load(model_name, device)

        print("[INFO] Loading the training and test dataset...")
        train_dataset = ImageFolder(root=args.train_data, transform=transform)
        test_dataset = ImageFolder(root=args.test_data, transform=transform)
        print("[INFO] Training dataset contains {} samples.".format(len(train_dataset)))
        print("[INFO] Test dataset contains {} samples.".format(len(test_dataset)))

        train_features, y_train = get_features(train_dataset, model, device)
        test_features, y_test = get_features(test_dataset, model, device)

        '''Bayesion hyperparameter tuning for regularization strength (C) parameter of Logistic Regression
           Hyperparameters are sampled by Tree-structured Parzen Estimator (TPESampler) '''
        study = optuna.create_study(sampler=TPESampler(), direction='maximize')
        study.optimize(lambda trial: objective(trial, train_features, y_train), n_trials=20)

        opt_reg_strength = study.best_trial.params['reg_strength']
        classifier = LogisticRegression(random_state=0, C=opt_reg_strength, max_iter=1000, verbose=0, class_weight='balanced', n_jobs=-1)
        classifier.fit(train_features, y_train)

        y_pred = classifier.predict(test_features)
        report = classification_report(y_test, y_pred, target_names=test_dataset.classes, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        report_df.to_csv('{}classification_report_{}.csv'.format(args.log_dir,model_name.replace("/", "_")), index=True)
        print(report)

        fig, ax = plt.subplots(figsize=(9, 8))
        cm = confusion_matrix(y_test, y_pred, normalize='true')
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.classes)
        disp.plot(xticks_rotation='vertical', ax=ax)
        fig.savefig('{}confusion_matrix_{}.jpg'.format(args.log_dir,model_name.replace("/", "_")))

        print("[INFO]: Training completed for model {} ...".format(model_name))


def get_features(dataset, model, device, batch_size = 32):
    '''
        THIS FUNCTION EXTRACTS THE FEATURES OF GIVEN IMAGES BY USING IMAGE_ENCODER METHOD OF THE GIVEN MODEL
        :param dataset: dataset object in ImageFolder type
        :param model: CLIP model to be exploited for feature extraction
        :param device: GPU or CPU device for placing the model
        :param batch_size: the size of each batches in data reading
        :return: returns the tuple of (extracted features, labels)
    '''

    all_features = []
    all_labels = []

    with torch.no_grad():
        for images, labels in tqdm(DataLoader(dataset, batch_size=batch_size)):
            features = model.encode_image(images.to(device))

            all_features.append(features)
            all_labels.append(labels)

    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument('--train-data', type=str, default='data/coco_crops_few_shot/train/')
    parser.add_argument('--test-data', type=str, default='data/coco_crops_few_shot/test/')
    parser.add_argument('--log-dir', type=str, default='logs/')
    parser.add_argument('--n-trials', type=int, default=1)
    parser.add_argument('--reg-strength', type=float, nargs='+', default=[0.005, 1, 0.005])

    args = parser.parse_args()

    main(args)



