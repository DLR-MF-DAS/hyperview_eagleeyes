"""
This code is generated by Ridvan Salih KUZU
LAST EDITED:  20.06.2022
ABOUT SCRIPT:
It defines Data Loader class and functions
"""

import torch
from clip.clip_dataset import ClIPDataset
from torch.utils.data import Subset
from sklearn.model_selection import train_test_split
from torchvision import transforms



class CLIPDataloader():
    """
    THIS CLASS ORCHESTRATES THE TRAINING, VALIDATION, AND TEST DATA GENERATORS
    """
    def __init__(self,
                 train_root,
                 test_root,
                 im_size=224,
                 split=0.30,
                 batch_size=64,
                 num_workers=1,
                 image_transform=True,
                 text_transform=True):


        trans_tr, trans_te = CLIPDataloader.train_test_transform(im_size, image_transform)

        train_dataset = ClIPDataset(root=train_root, transform=trans_tr,text_augmented=text_transform)
        tr_dataset, val_dataset = CLIPDataloader.train_val_dataset(train_dataset, split)
        test_dataset = ClIPDataset(root=test_root, transform=trans_te, text_augmented=text_transform)

        self.classes=test_dataset.classes
        self.dataloaders = {}

        self.dataloaders['all_train'] = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,
                                                                shuffle=True, num_workers=num_workers, pin_memory=True)

        self.dataloaders['train'] = torch.utils.data.DataLoader(tr_dataset,batch_size=batch_size,
                                                           shuffle=True, num_workers=num_workers, pin_memory=True)

        self.dataloaders['valid'] = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,
                                                           shuffle=True, num_workers=num_workers, pin_memory=True)

        self.dataloaders['test'] = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,
                                                           shuffle=False, num_workers=num_workers, pin_memory=True)

    def get_data_loader(self, type):
        return self.dataloaders[type]

    def get_classses(self):
        return self.classes

    @staticmethod
    def train_test_transform(im_size,is_image_transform=True):


        train_transform = transforms.Compose([
            transforms.Resize(size=im_size, interpolation=transforms.InterpolationMode.BILINEAR),
            transforms.RandomResizedCrop(im_size, scale=(0.75, 1.0), ratio=(0.75, 1.25),
                                                     interpolation=transforms.InterpolationMode.BILINEAR),
            transforms.CenterCrop(size=(im_size, im_size)),
            transforms.ColorJitter(hue=0.1),
            transforms.RandomHorizontalFlip(),
            transforms.RandomAffine(
                degrees=15,
                translate=(0.1, 0.1),
                scale=(0.8, 1.2),
                shear=(-15, 15, -15, 15),
                interpolation=transforms.InterpolationMode.BILINEAR,
                fill=127,
            ),
            transforms.RandomPerspective(
                distortion_scale=0.3,
                p=0.3,
                interpolation=transforms.InterpolationMode.BILINEAR,
                fill=127,
            ),
            transforms.RandomAutocontrast(p=0.3),
            transforms.RandomEqualize(p=0.3),
            transforms.ToTensor(),
            transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),
        ])

        test_transform = transforms.Compose([
            transforms.Resize(size=im_size, interpolation=transforms.InterpolationMode.BILINEAR),
            transforms.CenterCrop(size=(im_size, im_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),
        ])

        if is_image_transform:
            return train_transform, test_transform
        else:
            return test_transform, test_transform



    @staticmethod
    def train_val_dataset(dataset, val_split=0.20):
        train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)
        train_data = Subset(dataset, train_idx)
        valid_data = Subset(dataset, val_idx)
        return train_data,valid_data
